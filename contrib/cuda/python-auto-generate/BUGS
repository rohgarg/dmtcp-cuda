TODO (from Rohan's comments):
 - cudaMemcpy2D has multiple "size" arguments (for e.g.: Height x Width)
   There could be other such functions where there's no single "size"
   argument, rather multiple arguments are used to compose the
   final "size" argument. We need a mechanism for specifying this.
   [ *** THIS IS IMPLEMENTED NOW.  BUT I HAVE NOT TESTED COMPILING
        THE GENERATED C CODE. *** ]

 - Create CUDA_WRAPPER_WITH_LOGGING()
   [ *** THIS IS IMPLEMENTED NOW.  BUT I HAVE NOT TESTED COMPILING
        THE GENERATED C CODE.  ALSO, I'M GUESSING WHICH CUDA FNC'S
        SHOULD USE LOGGING.  FINALLY, I HAVE A SAMPLE file,
        log_append_and_read.cpp, IN WHICH i REWROTE THOSE FUNCTIONS
        TO BE COMPATIBLE WJTH THE auto-generated code. *** ]

At checkpoint time, we really should be copying from device memory
  to the application process just before writing the checkpoint.
Instead, it seems like we're still logging all of the cudaMemcpy's.
This is grossly inefficient, both at run time, and at restart time.
In particular, we have a struct called cudaSyscallStructure for logging.
  It is passed in as an argument.  This is really inefficient, because
  it means we're copying from the log file to a huge call frame on
  the stack, and then finally into the heap (I hope).
Apparently, we're doing this because we do not yet save the device pointers
  that were created.

cudaBindTexture2D - offset is :IN because the ptr might be NULL on input
        (meaning the output will not be set)
   I (Gene) had set it to :INOUT to capture that the ptr might be NULL
   on input.  It seems like we still have to handle that case.

cudaMallocHost, cudaHostAlloc -> don't use pinned memory;
	 just use malloc, and FIXME:  HACK!
  In this case, cudaFree() has to recognize that the memory was created
  by malloc() and simply call free() for these cases.  We
  need to keep some list of locally malloc'ed memory within the
  application process, to recognize such a malloc inside cudaFree().
  (Note that we will use CUDA_VERBATIM_WRAPPER(...) for these
  cudaMallocHost, cudaHostAlloc, and cudaFree functions.

cudaFreeArray generated code is assuming that the pointer to free
  is the same for the application process and for the proxy.
The other cudaFree functions probably have the same bug.
Should we virtualize pointers?
In fact, the pointers generated by malloc are different on the proxy
  and in the application process.

UVM (unified virtual memory) still has to be completed (based on catching
	SIGSEGV signal)

:OUT - > cudaMalloc
  Because the ptr is given as an :OUT parameter, the generated code
  executes cudaMalloc() on the proxy (which is correct), and then
  copies the uninitialized memory to the application process (which
  is inefficient).
    This is a performance bug that we can live with for now.

LOOK UP HANDLING FOR:
  ...Async...

====================================
FIXED (as of Mon.., Jan. 8):
  "EXTERNC" was appearing in body of functions; fixed
  main.template had repeated "cudaError_t" for function type, and  missing ')'

FIXED (as of Sat.., Jan. 6):
  cudaMemcpy2D implemented
  CUDA_WRAPPER_WITH_LOGGING implemented
  Ignore default optional args for fnc's such as
     cudaMallocArray and cudaMemcpyAsync

FIXED (as of Thurs.., Jan. 4):
ADDED: CUDA_VERBATIM_WRAPPER() and CUDA_VERBATIM_PROXY()
chars_rcvd = 0; -> Place this after:
  // Extract OUT variables
  (and not just before it, as it is now.)
memcpy(ret_val, ...) -> memcpy(&ret_val, ...)
sizeof cuda_op -> sizeof enum cuda_op

FIXED (as of Wed., Jan. 3):
Don't emit '// Extract OUT variables' if no 'OUT' variables
cudaMemcpy -> read payload only after reading ret_val
char_sent -> chars_sent
end of function -> Add a blank line after final '};'

====
cudaproxy.icu

Don't return ret_val from FNC_XXX since it has void return value.
Return type added:  void FNC_XXX
New line after '}' end of fnc
Function of no arguments now specifices 'void':  void FNC_XXX(void);


Ones' comments:
  Bugs found
====================================
- dmtcp-cuda/contrib/cuda/cuda-plugin.cpp +86
In the current version we are nolonger using the cudaSyscallsStructure
we are instead using a fixed size buffer to hold the args we want
to send and/or receive.
The restart() function in cuda-plugin.cpp seems to be using the
obselete version of log_read().
FIXED (as of Tues., Jan 9):

- dmtcp-cuda/contrib/cuda/cuda-uvm-utils.cpp +82
The UVM implementation is not up-to-date with the current design.
It is still using "send_recv()".
For testing purpose, I am copying "send_recv()" in the scope of
python-auto-generate code.
FIXED (not yet: after UVM implementation)

- log_append() in cudaMallocManaged()
UVM is still following the obsolete design.
For now, I will used dummy args in log_append.
FIXED (not yet: during UVM implementation)

- dmtcp-cuda/contrib/cuda/python-autogenerate/cudaproxy.icpp
inside FNC_cudaMemcpyToArray():
dst = malloc() should insted be dst = (cudaArray_t) malloc().
I fixed this in the source code but the script should also
be updated.
FIXED (not yet: to be done by Gene)
